from pydub import AudioSegment
import numpy as np
# from scipy.signal.signaltools import wiener
from scipy.fft import fft, ifft
from scipy import signal
import torch
from audio_preprocess import audio_to_psd


def audio_to_spectrogram(tensor_sound, fr=4800, time_window=0.02, time_overlap=0.01, lpass: 'bool, low passã®å‡¦ç†ã‚’ã™ã‚‹ã‹ã©ã†ã‹' = False, lpass_thresh=10000):
    '''
    stPSDã‚’è¿”ã™ã€‚è¿”ã‚Šå€¤ã¯dim=2ã®ndarray. axis=0æ–¹å‘ã¯å„ãƒ•ãƒ¬ãƒ¼ãƒ . axis=1æ–¹å‘ã¯ãã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã®stPSD.
    '''
    x = tensor_sound.numpy()

    # %%
    NFFT = int(fr * time_window)  # ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¤§ãã•
    OVERLAP = NFFT // 2  # çª“ã‚’ãšã‚‰ã—ãŸæ™‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®é‡ãªã‚Šå…·åˆ. half shiftãŒä¸€èˆ¬çš„ã‚‰ã—ã„
    frame_length = x.shape[0]  # wavãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    time_song = float(frame_length) / fr  # æ³¢å½¢é•·ã•(ç§’)
    time_unit = 1 / float(fr)  # 1ã‚µãƒ³ãƒ—ãƒ«ã®é•·ã•(ç§’)

    # ğŸ’¥ 1.
    # FFTã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ™‚é–“ã‚’æ±ºã‚ã¦ã„ãã¾ã™
    # time_rulerã«å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä¸­å¿ƒæ™‚é–“ãŒå…¥ã£ã¦ã„ã¾ã™
    start = (NFFT / 2) * time_unit
    stop = time_song
    step = (NFFT - OVERLAP) * time_unit
    time_ruler = np.arange(start, stop, step)

    # ğŸ’¥ 2.
    # çª“é–¢æ•°ã¯å‘¨æ³¢æ•°è§£åƒåº¦ãŒé«˜ã„ãƒãƒŸãƒ³ã‚°çª“ã‚’ç”¨ã„ã¾ã™
    window = np.hamming(NFFT)

    spec = np.zeros([len(time_ruler), 1 + int(NFFT / 2)])  # è»¢ç½®çŠ¶æ…‹ã§å®šç¾©åˆæœŸåŒ–
    pos = 0

    for fft_index in range(len(time_ruler)):
        # ğŸ’¥ 1.ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ‡ã‚Šå‡ºã—ã¾ã™
        frame = x[pos:pos + NFFT]
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒä¿¡å·ã‹ã‚‰åˆ‡ã‚Šå‡ºã›ãªã„æ™‚ã¯ã‚¢ã‚¦ãƒˆã§ã™
        if len(frame) == NFFT:
            # ğŸ’¥ 2.çª“é–¢æ•°ã‚’ã‹ã‘ã¾ã™
            windowed = window * frame
            # ğŸ’¥ 3.FFTã—ã¦å‘¨æ³¢æ•°æˆåˆ†ã‚’æ±‚ã‚ã¾ã™
            # rfftã ã¨éè² ã®å‘¨æ³¢æ•°ã®ã¿ãŒå¾—ã‚‰ã‚Œã¾ã™
            fft_result = np.fft.rfft(windowed)
            # ğŸ’¥ 4.å‘¨æ³¢æ•°ã«ã¯è™šæ•°æˆåˆ†ã‚’å«ã‚€ã®ã§çµ¶å¯¾å€¤ã‚’absã§æ±‚ã‚ã¦ã‹ã‚‰2ä¹—ã—ã¾ã™
            # ã‚°ãƒ©ãƒ•ã§è¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ã«å¯¾æ•°ã‚’ã¨ã‚Šã¾ã™
            fft_data = np.log(np.abs(fft_result) ** 2)
            # fft_data = np.log(np.abs(fft_result))
            # fft_data = np.abs(fft_result) ** 2
            # fft_data = np.abs(fft_result)
            # ã“ã‚Œã§æ±‚ã‚ã‚‰ã‚Œã¾ã—ãŸã€‚ã‚ã¨ã¯specã«æ ¼ç´ã™ã‚‹ã ã‘ã§ã™
            for i in range(len(spec[fft_index])):
                spec[fft_index][-i - 1] = fft_data[i]

            # ğŸ’¥ 4. çª“ã‚’ãšã‚‰ã—ã¦æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¸
            pos += (NFFT - OVERLAP)
    clipped_spec = spec[:, 150:400]
    mean = np.mean(clipped_spec)
    std = np.std(clipped_spec)
    reg_spec = (clipped_spec - mean) / std
    return reg_spec


def make_batch_spectrogram(X_train):
    ans = []
    for i in X_train:
        ans.append(audio_to_spectrogram(i))
    return torch.Tensor(np.array(ans))


def make_batch_stpsd(X_train):
    ans = []
    for i in X_train:
        ans.append(audio_to_stpsd(i))
    return torch.Tensor(np.array(ans))
